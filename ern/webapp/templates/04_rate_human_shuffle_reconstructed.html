{% extends "base.html" %}

{% block content %}

<h1>Task 3: Rating the model's reconstruction of your shuffle</h1>
<p class="fw-italic">Sample - {{ sample_id }} </p>

<p>A Large Language Model has attempted to reconstruct your story.

Your task is to rate how well the model has done so on three points:</p>

<h4>Flow</h4>
<p>How well has the model reconstructed the story?
A score of 0 means that the model has made many mistakes or produced garbage output, while a score of 10 means that the model has successfully reconstructed the logical ordering of the story.</p>

<h4>Fluency</h4>
<p>It is possible that the model rewrote (some parts of) the story in a way that is grammatically incorrect or awkward.
A score of 0 means that the model has made many mistakes or produced garbage output.
A score of 10 means that the model has made minimal modifications, perhaps appropriately correcting a typo or two.</p>

<h4>Accuracy</h4>
<p>The factual accuracy of the story. That is, did the model add or remove information that was not present in the original story?
A score of 0 means that the model has fabricated information, while a score of 10 means that the model has not added or removed any information.</p>

<h2>Your original story</h2>
<div class="container">
        {% for sentence in tokenized_story_text %}
        <div class="box">{{ sentence }}</div>
        {% endfor %}
</div>

<h2>The LLM's reconstruction</h2>
<div class="container">
        {% for sentence in tokenized_human_reconstructed_story %}
        <div class="box">{{ sentence }}</div>
        {% endfor %}
</div>

<form action="{% url 'rate_human_shuffle_reconstructed' %}" method="post">
    {% csrf_token %}
    {{ form }}
</form>

{% endblock %}